{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_columns_with_default(df, columns, columns_to_fill, values):\n",
    "    copy_df = df.copy()\n",
    "    unique_columns = [copy_df[col].unique() for col in columns]\n",
    "    index = pd.MultiIndex.from_product(unique_columns,names=columns)\n",
    "    new_df = pd.DataFrame(index=index, columns=['count'])\n",
    "    merged_df = pd.merge(copy_df, new_df, how='right', left_on=columns, right_index=True)\n",
    "    for idx,col in enumerate(columns_to_fill):\n",
    "        merged_df[col] = merged_df[col].fillna(values[idx])\n",
    "    return merged_df\n",
    "\n",
    "def get_gdp_data(df_gdp: pd.DataFrame, df_disaster: pd.DataFrame, years, country = None, categories = False):\n",
    "    columns = years + ['Country Code']\n",
    "    columns = [str(c) for c in columns]\n",
    "    gdp_data_filtered = df_gdp[columns]\n",
    "    if (country):\n",
    "        gdp_data_reduced = gdp_data_filtered[gdp_data_filtered['Country Code'] == country]\n",
    "        disaster_columns = ['Start Year', 'ISO']\n",
    "        if (categories): disaster_columns += ['Disaster Subgroup', 'Disaster Type']\n",
    "        disaster_data_by_year = df_disaster.groupby(disaster_columns, as_index=False).sum(numeric_only=True)\n",
    "        disaster_data_by_year = disaster_data_by_year[disaster_data_by_year['ISO'] == country] \n",
    "    else:\n",
    "        disaster_columns = ['Start Year']\n",
    "        if (categories): disaster_columns += ['Disaster Subgroup', 'Disaster Type']\n",
    "        gdp_data_reduced = pd.DataFrame([gdp_data_filtered.mean(numeric_only=True)], columns=[str(y) for y in years])\n",
    "        disaster_data_by_year = df_disaster.groupby(disaster_columns, as_index=False).sum(numeric_only=True)\n",
    "        disaster_data_by_year['ISO'] = 'WORLD'\n",
    "\n",
    "    def calculate_gdp_share(row):\n",
    "        year = str(int(row['Start Year']))\n",
    "        if (not (year in gdp_data_reduced.columns)):\n",
    "            return 0\n",
    "        gdp = gdp_data_reduced[year]\n",
    "        if (gdp.empty):\n",
    "            return 0\n",
    "        damages = row[\"Total Damages, Adjusted ('000 US$)\"] * 1000\n",
    "        return (damages / gdp) * 100\n",
    "\n",
    "    columns_to_fill = ['Start Year', 'ISO', 'Disaster Subgroup', 'Disaster Type']\n",
    "\n",
    "    if (disaster_data_by_year.empty):\n",
    "        disaster_data_by_year[\"share\"] = 0\n",
    "    else:\n",
    "        disaster_data_by_year['share'] = disaster_data_by_year.apply(calculate_gdp_share, axis=1)\n",
    "\n",
    "    if categories:\n",
    "        filled_df = fill_missing_columns_with_default(disaster_data_by_year,columns_to_fill,[\"Total Damages, Adjusted (\\'000 US$)\", 'share'],[0,0])\n",
    "        return filled_df\n",
    "    return disaster_data_by_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_years(df,years,country, disaster_classification): \n",
    "    all_combinations = [(year, country, disaster_subgroup, disaster_type) for disaster_subgroup, disaster_types in disaster_classification.items() for disaster_type in disaster_types for year in years]\n",
    "    all_combinations_df = pd.DataFrame(all_combinations, columns=['Start Year', 'ISO', 'Disaster Subgroup', 'Disaster Type'])\n",
    "    merged_df = pd.merge(df, all_combinations_df,on=['Start Year', 'ISO', 'Disaster Subgroup', 'Disaster Type'], how=\"right\")\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gdp = pd.read_csv('../gdp_data_constant.csv')\n",
    "df_disaster = pd.read_csv('../Preprocessed-Natural-Disasters.csv',delimiter=';')\n",
    "for year in range(1960, 2024):\n",
    "    df_gdp.loc[:, str(year)] = df_gdp.loc[:, str(year)] * 1.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "disaster_subgroups = df_disaster['Disaster Subgroup'].unique()\n",
    "disaster_types = df_disaster['Disaster Type'].unique()\n",
    "\n",
    "disaster_classification = {dis_subgroup: list(df_disaster[df_disaster[\"Disaster Subgroup\"] == dis_subgroup][\"Disaster Type\"].unique()) for dis_subgroup in df_disaster['Disaster Subgroup'].unique()}\n",
    "\n",
    "isos = df_disaster['ISO'].unique()\n",
    "\n",
    "years = list(range(1960,2023))\n",
    "\n",
    "total_gdp_df = pd.DataFrame()\n",
    "for iso in isos:\n",
    "    gdp_data = get_gdp_data(df_gdp,df_disaster,years,country=iso,categories=True)\n",
    "    gdp_data = gdp_data[['Start Year', 'ISO', 'Disaster Subgroup', 'Disaster Type','share']]\n",
    "    gdp_data = fill_years(gdp_data,years,iso, disaster_classification)\n",
    "    gdp_data.fillna(0,inplace=True)\n",
    "    total_gdp_df = pd.concat([total_gdp_df, gdp_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_gdp_df.to_csv('../gdp_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "info_vis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
